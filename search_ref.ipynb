{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm_call(model, messages, **call_args):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        **call_args\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def create_batch_req_object(req_id, model, messages, response_format, temperature=0.0):\n",
    "    return {\n",
    "       \"custom_id\": req_id,\n",
    "       \"method\": \"POST\",\n",
    "       \"url\": \"/v1/chat/completions\",\n",
    "       \"body\": {\n",
    "          \"model\": model, \n",
    "          \"messages\": messages,\n",
    "          \"temperature\": temperature,\n",
    "          \"response_format\": response_format,\n",
    "        }\n",
    "    }\n",
    "\n",
    "def llm_batch_api(batch_filepath, purpose=\"\", desc=\"\", completion_window=\"24h\"):\n",
    "    batch_input_file = client.files.create(\n",
    "      file=open(batch_filepath, \"rb\"),\n",
    "      purpose=purpose\n",
    "    )\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    batch_info = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=completion_window,\n",
    "        metadata={\n",
    "          \"description\": desc\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return batch_info\n",
    "\n",
    "def llm_batch_check_retrieve(batch_info):\n",
    "    updated_batch = client.batches.retrieve(batch_info.id)\n",
    "    print(f\"Status of batch {updated_batch.id} is {updated_batch.status}\")\n",
    "    if updated_batch.status == \"completed\":\n",
    "      output_file = client.files.content(updated_batch.output_file_id)\n",
    "      return updated_batch, output_file\n",
    "    else:\n",
    "      return updated_batch, None\n",
    "\n",
    "def llm_batch_check_retrieve_dict(batch_info):\n",
    "    updated_batch = client.batches.retrieve(batch_info[\"id\"])\n",
    "    print(f\"Status of batch {updated_batch.id} is {updated_batch.status}\")\n",
    "    if updated_batch.status == \"completed\":\n",
    "      output_file = client.files.content(updated_batch.output_file_id)\n",
    "      return updated_batch, output_file\n",
    "    else:\n",
    "      return updated_batch, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "def num_tokens_from_string(string: str, encoder) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    num_tokens = len(encoder.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def count_tokens_in_dataset(dataset, num_tokens_from_string, encoder):\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for item in dataset:\n",
    "        text = item['text']\n",
    "        tokens = num_tokens_from_string(text, encoder)\n",
    "        total_tokens += tokens\n",
    "    \n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(data_string, output_file):\n",
    "    \"\"\"\n",
    "    Writes JSONL string to a file.\n",
    "    \n",
    "    Args:\n",
    "        data_string (str): String containing JSONL data\n",
    "        output_file (str): Path to output file\n",
    "    \"\"\"\n",
    "    # Split the string into lines and filter out empty lines\n",
    "    json_lines = [line.strip() for line in data_string.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Write each line to the file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for line in json_lines:\n",
    "            json_obj = json.loads(line)  # Parse the JSON string\n",
    "            f.write(json.dumps(json_obj) + '\\n')  # Write formatted JSON\n",
    "\n",
    "def read_jsonl(input_file):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and returns a list of JSON objects.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input JSONL file\n",
    "        \n",
    "    Returns:\n",
    "        list: List of parsed JSON objects\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Function to save the batch object using pickle\n",
    "def save_batch_to_pickle(batch_obj, output_file=\"batch_data.pkl\"):\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(batch_obj, f)\n",
    "\n",
    "# Function to load the batch object from a pickle file\n",
    "def load_batch_from_pickle(input_file=\"batch_data.pkl\"):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def create_batches(dataset, batch_size=1000):\n",
    "    return [dataset.select(range(i, min(i + batch_size, len(dataset)))) for i in range(0, len(dataset), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_gen_search_keyword(str_dict):\n",
    "    sys_prompt = \"Always answer in a valid JSON format following the user instructions, without any introduction, commentary, or anything else, only the JSON answer.\"\n",
    "    prompt = f\"\"\"You are a master in Indonesian and Javanese Language. Now, you are given a Cirebonese word with its translation or definition in Indonesian. The word is:\n",
    "\n",
    "<cbn_word>\n",
    "{str_dict}\n",
    "</cbn_word>\n",
    "    \n",
    "What you need to do is to convert the word into list of searchable keywords to search on Google. At least one search keyword must contain the cirebonese word. The search keyword also need to be relevant to Indonesian and Cirebonese specifically to the word meaning, also surely will return some results when searching in the internet. Return in JSON format with key \"search_keyword\" and the list of search keyword as the value.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=512,\n",
    "        temperature=1,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def batch_gen_search_keyword(str_dict):\n",
    "    sys_prompt = \"Always answer in a valid JSON format following the user instructions, without any introduction, commentary, or anything else, only the JSON answer.\"\n",
    "    prompt = f\"\"\"You are a master in Indonesian and Javanese Language. Now, you are given a Cirebonese word with its translation or definition in Indonesian. The word is:\n",
    "\n",
    "<cbn_word>\n",
    "{str_dict}\n",
    "</cbn_word>\n",
    "    \n",
    "What you need to do is to convert the word into list of searchable keywords to search on Google. At least one search keyword must contain the cirebonese word. The search keyword also need to be relevant to Indonesian and Cirebonese specifically to the word meaning, also surely will return some results when searching in the internet. Return in JSON format with key \"search_keyword\" and the list of search keyword as the value.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    model = \"gpt-4o-mini-2024-07-18\"\n",
    "    temperature = 1\n",
    "    max_tokens = 512\n",
    "    response_format = {\"type\": \"json_object\"}\n",
    "    \n",
    "    return messages, model, temperature, max_tokens, response_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# filepath: /f:/dev/cirebonese/dict/cbn_idn.json\n",
    "with open('./dict/cbn_idn.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize the counter dictionary\n",
    "counter = defaultdict(int)\n",
    "\n",
    "# Function to get a random word and its translations/definitions\n",
    "def get_random_word(data, counter):\n",
    "    word = random.choice(list(data.keys()))\n",
    "    counter[word] += 1\n",
    "    return word\n",
    "\n",
    "# Function to format the selected word and its translations/definitions\n",
    "def format_word(word, data):\n",
    "    result = f\"{word}:\\n\"\n",
    "    for translation in data[word]:\n",
    "        result += f\"  - {translation}\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upaper:\n",
      "  - cepat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = get_random_word(data, counter)\n",
    "formatted_string = format_word(word, data)\n",
    "print(formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gen_search_keyword(formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"search_keyword\": [\n",
      "    \"pamêg permainan\",\n",
      "    \"permainan tradisional Cirebon\",\n",
      "    \"permainan Cirebon\",\n",
      "    \"jenis permainan di Indonesia\",\n",
      "    \"permainan anak Cirebon\",\n",
      "    \"permainan budaya Cirebon\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize the get_random_word to randomly choose a word from the dict\n",
    "batch_req_objects = []\n",
    "total_words = len(data)\n",
    "while any(count < 2 for count in counter.values()) or not bool(counter.values()):\n",
    "    word = get_random_word(data, counter)\n",
    "    formatted_string = format_word(word, data)\n",
    "    \n",
    "    # Use the formatted string in the prompt in batch_gen_search_keyword and obtain the batch info\n",
    "    messages, model, temperature, max_tokens, response_format = batch_gen_search_keyword(formatted_string)\n",
    "    \n",
    "    # Convert into batch req object using create_batch_req_object\n",
    "    batch_req_object = create_batch_req_object(req_id=f\"req_{word}_{counter[word]}\", model=model, messages=messages, response_format=response_format, temperature=temperature)\n",
    "    \n",
    "    # Gather the batch req object in a list\n",
    "    batch_req_objects.append(batch_req_object)\n",
    "\n",
    "# Write all the batch req objects into a jsonl file using write_jsonl\n",
    "batch_req_objects_jsonl = \"\\n\".join([json.dumps(obj) for obj in batch_req_objects])\n",
    "write_jsonl(batch_req_objects_jsonl, \"gen_search_batch.jsonl\")\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192678"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_req_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': 'req_gêring_2',\n",
       " 'method': 'POST',\n",
       " 'url': '/v1/chat/completions',\n",
       " 'body': {'model': 'gpt-4o-mini-2024-07-18',\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Always answer in a valid JSON format following the user instructions, without any introduction, commentary, or anything else, only the JSON answer.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'You are a master in Indonesian and Javanese Language. Now, you are given a Cirebonese word with its translation or definition in Indonesian. The word is:\\n\\n<cbn_word>\\ngêring:\\n  - sakit\\n\\n</cbn_word>\\n    \\nWhat you need to do is to convert the word into list of searchable keywords to search on Google. At least one search keyword must contain the cirebonese word. The search keyword also need to be relevant to Indonesian and Cirebonese specifically to the word meaning, also surely will return some results when searching in the internet. Return in JSON format with key \"search_keyword\" and the list of search keyword as the value.'}],\n",
       "  'temperature': 1,\n",
       "  'response_format': {'type': 'json_object'}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_req_objects[21378]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_info = llm_batch_api(\"gen_search_batch.jsonl\", purpose=\"batch\", desc=\"Batch of requests to generate search keywords for Cirebonese words\", completion_window=\"24h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of batch batch_67ac193a60d8819098380df4bc7ff5a6 is failed\n"
     ]
    }
   ],
   "source": [
    "batch_info, updated_batch = llm_batch_check_retrieve(batch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_objects = read_jsonl(\"gen_search_batch.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batches_to_jsonl(batch_req_objects, batch_size, base_filename):\n",
    "    # Divide the batch_req_objects into smaller lists with the specified batch size\n",
    "    for i in range(0, len(batch_req_objects), batch_size):\n",
    "        batch = batch_req_objects[i:i + batch_size]\n",
    "        batch_filename = f\"{base_filename}_batch_{i // batch_size + 1}.jsonl\"\n",
    "        \n",
    "        # Convert the batch to JSONL format\n",
    "        batch_jsonl = \"\\n\".join([json.dumps(obj) for obj in batch])\n",
    "        \n",
    "        # Write the batch to a .jsonl file\n",
    "        write_jsonl(batch_jsonl, batch_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_batches_to_jsonl(batch_objects, 50000, \"batch_requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the llm_batch_api function with all .jsonl files and gather batch_info\n",
    "batch_files = [f for f in os.listdir() if f.startswith(\"batch_requests_batch_\") and f.endswith(\".jsonl\")]\n",
    "all_batch_info = []\n",
    "for batch_file in batch_files:\n",
    "    batch_number = batch_file.split('_')[-1].split('.')[0]\n",
    "    desc = f\"Batch {batch_number} of requests to generate search keywords for Cirebonese words\"\n",
    "    batch_info = llm_batch_api(batch_file, purpose=\"batch\", desc=desc, completion_window=\"24h\")\n",
    "    all_batch_info.append(batch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert batch_info objects to a JSON-serializable format\n",
    "all_batch_info_serializable = [batch_info.to_dict() for batch_info in all_batch_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all batch_info to a file\n",
    "with open(\"all_batch_info.json\", \"w\") as f:\n",
    "    json.dump(all_batch_info_serializable, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_batch_info.json', 'r', encoding='utf-8') as file:\n",
    "    all_batch_info = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of batch batch_67ac37dbdfb081909467ebe322b86904 is in_progress\n",
      "Batch(id='batch_67ac37dbdfb081909467ebe322b86904', completion_window='24h', created_at=1739339739, endpoint='/v1/chat/completions', input_file_id='file-3j5YFNshfg66LDAsGczR6f', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739426139, failed_at=None, finalizing_at=None, in_progress_at=1739339751, metadata={'description': 'Batch 1 of requests to generate search keywords for Cirebonese words'}, output_file_id=None, request_counts=BatchRequestCounts(completed=49153, failed=0, total=50000))\n",
      "Status of batch batch_67ac37e5a400819085905be69807282f is in_progress\n",
      "Batch(id='batch_67ac37e5a400819085905be69807282f', completion_window='24h', created_at=1739339749, endpoint='/v1/chat/completions', input_file_id='file-QySTAxjN34tDT77gxLCcbT', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739426149, failed_at=None, finalizing_at=None, in_progress_at=1739339764, metadata={'description': 'Batch 2 of requests to generate search keywords for Cirebonese words'}, output_file_id=None, request_counts=BatchRequestCounts(completed=49880, failed=0, total=50000))\n",
      "Status of batch batch_67ac37ef9e448190ae722c6ab9596078 is in_progress\n",
      "Batch(id='batch_67ac37ef9e448190ae722c6ab9596078', completion_window='24h', created_at=1739339759, endpoint='/v1/chat/completions', input_file_id='file-7VsTooq3Zyo5g38q6WeQY5', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1739426159, failed_at=None, finalizing_at=None, in_progress_at=1739339770, metadata={'description': 'Batch 3 of requests to generate search keywords for Cirebonese words'}, output_file_id=None, request_counts=BatchRequestCounts(completed=49522, failed=0, total=50000))\n",
      "Status of batch batch_67ac37f8cc788190a305f2dac032b176 is completed\n",
      "Batch(id='batch_67ac37f8cc788190a305f2dac032b176', completion_window='24h', created_at=1739339768, endpoint='/v1/chat/completions', input_file_id='file-XbAWz9ZKN7BzqutkZWYfQm', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1739353219, error_file_id=None, errors=None, expired_at=None, expires_at=1739426168, failed_at=None, finalizing_at=1739348032, in_progress_at=1739339776, metadata={'description': 'Batch 4 of requests to generate search keywords for Cirebonese words'}, output_file_id='file-VhPCdQjCW7RPiBk8Hb9sD4', request_counts=BatchRequestCounts(completed=42678, failed=0, total=42678))\n"
     ]
    }
   ],
   "source": [
    "for batch in all_batch_info:\n",
    "    updated_batch, output_file = llm_batch_check_retrieve_dict(batch)\n",
    "    print(updated_batch)\n",
    "    if output_file:\n",
    "        write_jsonl(output_file.text, f\"batch_output_{updated_batch.metadata['description'].split()[1]}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_batch.metadata['description'].split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
